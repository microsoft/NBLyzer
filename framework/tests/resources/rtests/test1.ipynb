{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "859bd85e-a886-4a5a-bb18-a6efee0010c7",
    "_uuid": "b71062412ed7a39b993a20b756b9d4fdb9a78426",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c8699e812346>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m# linear algebra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[1;31m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import neighbors\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fb6663ad-72aa-4224-9585-79cad44bb0a3",
    "_uuid": "136942079e1bb90fbb48402ea0a4c4537a69a7b8",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Start of by reading in the data and merging the datasets\n",
    "prop = pd.read_csv('../input/properties_2016.csv')\n",
    "train = pd.read_csv(\"../input/train_2016_v2.csv\")\n",
    "\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\t\n",
    "    if dtype == np.float64:\t\t\n",
    "        prop[c] = prop[c].astype(np.float32)\n",
    "\n",
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "del prop, train\n",
    "df_train = df_train.drop(['parcelid', 'transactiondate'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7288c403-6102-45b1-98c3-9132ef508404",
    "_uuid": "d27835fce1f19a272e0b8e617fd2552c0f4c489a",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "missing_df = df_train.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df.loc[missing_df['missing_count']>0]\n",
    "missing_df = missing_df.sort_values(by='missing_count')\n",
    "\n",
    "ind = np.arange(missing_df.shape[0])\n",
    "width = 0.9\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "rects = ax.barh(ind, missing_df.missing_count.values, color='blue')\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\n",
    "ax.set_xlabel(\"Count of missing values\")\n",
    "ax.set_title(\"Number of missing values in each column\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "372ddaed-762d-461c-a749-3f40f20bccc8",
    "_uuid": "e57adcb28509ce9834423f16dd3ef0a4e592493f",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#'calculatedfinishedsquarefeet' has the fewest missing values so lets remove the others, note also that except for 'finishedsquarefeet12' the rest have large amount of missing values anyways. \n",
    "#Also if you look at my script in https://www.kaggle.com/nikunjm88/creating-additional-features 'calculatedfinishedsquarefeet' appears to be the most important variable\n",
    "dropcols = ['finishedsquarefeet12','finishedsquarefeet13', 'finishedsquarefeet15','finishedsquarefeet6']\n",
    "\n",
    "#finishedsquarefeet50 and finishedfloor1squarefeet are the exactly the same information according to the dictionary descriptions, lets remove finishedsquarefeet50 as it has more missing values\n",
    "dropcols.append('finishedsquarefeet50')\n",
    "\n",
    "#'bathroomcnt' and 'calculatedbathnbr' and 'fullbathcnt' seem to be the same information aswell according to the dictionary descriptions. Choose 'bathroomcnt' as has no missing values, so remove the other two\n",
    "dropcols.append('calculatedbathnbr')\n",
    "dropcols.append('fullbathcnt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8698a8f6-5061-49b7-b122-460db1ba8fa1",
    "_uuid": "1743b92255a9258b4cd537f51223372b060e2128",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#The below variables are flags and lets assume if they are NA's it means the object does not exist so lets fix this\n",
    "index = df_train.hashottuborspa.isnull()\n",
    "df_train.loc[index,'hashottuborspa'] = \"None\"\n",
    "\n",
    "#lets remove 'pooltypeid10' as has more missing values\n",
    "dropcols.append('pooltypeid10')\n",
    "\n",
    "#Assume if the pooltype id is null then pool/hottub doesnt exist \n",
    "index = df_train.pooltypeid2.isnull()\n",
    "df_train.loc[index,'pooltypeid2'] = 0\n",
    "\n",
    "index = df_train.pooltypeid7.isnull()\n",
    "df_train.loc[index,'pooltypeid7'] = 0\n",
    "\n",
    "index = df_train.poolcnt.isnull()\n",
    "df_train.loc[index,'poolcnt'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f40db0e5-3c6c-4cd9-9b03-3b41574835b6",
    "_uuid": "4a9a888d63f91aa17b0708c430acd0839d8d7115",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Fill in those properties that have a pool with median pool value\n",
    "poolsizesum_median = df_train.loc[df_train['poolcnt'] > 0, 'poolsizesum'].median()\n",
    "df_train.loc[(df_train['poolcnt'] > 0) & (df_train['poolsizesum'].isnull()), 'poolsizesum'] = poolsizesum_median\n",
    "\n",
    "#If it doesn't have a pool then poolsizesum is 0 by default\n",
    "df_train.loc[(df_train['poolcnt'] == 0), 'poolsizesum'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2ecdb041-57e0-4155-aaea-e3bde9215e0a",
    "_uuid": "d852f1724594e9eb035f946cb5356453fa7286c9",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#There seems to be 80668 properties without fireplace according to the 'fireplacecnt' but the 'fireplace flag' says they are 90053 missing values\n",
    "#Lets instead create the fireplaceflag from scratch using 'fireplacecnt' as there are less missing values here\n",
    "df_train['fireplaceflag']= \"No\"\n",
    "df_train.loc[df_train['fireplacecnt']>0,'fireplaceflag']= \"Yes\"\n",
    "\n",
    "index = df_train.fireplacecnt.isnull()\n",
    "df_train.loc[index,'fireplacecnt'] = 0\n",
    "\n",
    "#Tax deliquency flag - assume if it is null then doesn't exist\n",
    "index = df_train.taxdelinquencyflag.isnull()\n",
    "df_train.loc[index,'taxdelinquencyflag'] = \"None\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9674a6c7-d5dd-4ba2-9866-4a39934cb728",
    "_uuid": "ce5bc928baed8b4d2a46279ea6345a1ac79dc122",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Assume if Null in garage count it means there are no garages\n",
    "index = df_train.garagecarcnt.isnull()\n",
    "df_train.loc[index,'garagecarcnt'] = 0\n",
    "\n",
    "#Likewise no garage means the size is 0 by default\n",
    "index = df_train.garagetotalsqft.isnull()\n",
    "df_train.loc[index,'garagetotalsqft'] = 0\n",
    "\n",
    "#Let's fill in some missing values using the most common value for those variables where this might be a sensible approach\n",
    "#AC Type - Mostly 1's, which corresponds to central AC. Reasonable to assume most other properties are similar.\n",
    "df_train['airconditioningtypeid'].value_counts()\n",
    "index = df_train.airconditioningtypeid.isnull()\n",
    "df_train.loc[index,'airconditioningtypeid'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d5727552-cacd-4d50-9284-3276788d4f03",
    "_uuid": "c8bbfe333cfde2aed9bea575bb2bd7a5673bcd35",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#heating or system - Mostly 2, which corresponds to central heating so seems reasonable to assume most other properties have central heating  \n",
    "print(df_train['heatingorsystemtypeid'].value_counts())\n",
    "index = df_train.heatingorsystemtypeid.isnull()\n",
    "df_train.loc[index,'heatingorsystemtypeid'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04636d05-72c0-4766-99ef-2a7db515766d",
    "_uuid": "54996bd68351778f614f612513a297b1e114e1b4",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 'threequarterbathnbr' - not an important variable according to https://www.kaggle.com/nikunjm88/creating-additional-features, so fill with most common value\n",
    "print(df_train['threequarterbathnbr'].value_counts())\n",
    "index = df_train.threequarterbathnbr.isnull()\n",
    "df_train.loc[index,'threequarterbathnbr'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b7152b0e-c1e8-4ad2-991e-e6b66f970e56",
    "_uuid": "17e0eb07baaceea33c0d980d1584b100e996a8ec",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "missingvalues_prop = (df_train.isnull().sum()/len(df_train)).reset_index()\n",
    "missingvalues_prop.columns = ['field','proportion']\n",
    "missingvalues_prop = missingvalues_prop.sort_values(by = 'proportion', ascending = False)\n",
    "print(missingvalues_prop)\n",
    "missingvaluescols = missingvalues_prop[missingvalues_prop['proportion'] > 0.97].field.tolist()\n",
    "dropcols = dropcols + missingvaluescols\n",
    "df_train = df_train.drop(dropcols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e75eb17-2c18-465a-9ad0-192d37e36311",
    "_uuid": "69bfec676ce1b03959ef57970b2f26b317f62539",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#buildingqualitytypeid - assume it is the similar to the nearest property. Probably makes senses if its a property in a block of flats, i.e if block was built all at the same time and therefore all flats will have similar quality \n",
    "#Use the same logic for propertycountylandusecode (assume it is same as nearest property i.e two properties right next to each other are likely to have the same code) & propertyzoningdesc. \n",
    "#These assumptions are only reasonable if you actually have nearby properties to the one with the missing value\n",
    "\n",
    "fillna_knn( df = df_train,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'buildingqualitytypeid', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "\n",
    "zoningcode2int( df = df_train,\n",
    "                            target = 'propertycountylandusecode' )\n",
    "fillna_knn( df = df_train,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'propertycountylandusecode', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "zoningcode2int( df = df_train,\n",
    "                            target = 'propertyzoningdesc' )\n",
    "\n",
    "fillna_knn( df = df_train,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'propertyzoningdesc', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#regionidcity, regionidneighborhood & regionidzip - assume it is the same as the nereast property. \n",
    "#As mentioned above, this is ok if there's a property very nearby to the one with missing values (I leave it up to the reader to check if this is the case!)\n",
    "fillna_knn( df = df_train,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'regionidcity', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "fillna_knn( df = df_train,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'regionidneighborhood', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "fillna_knn( df = df_train,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'regionidzip', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#unitcnt - the number of structures the unit is built into. Assume it is the same as the nearest properties. If the property with missing values is in a block of flats or in a terrace street then this is probably ok - but again I leave it up to the reader to check if this is the case!\n",
    "fillna_knn( df = df_train,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'unitcnt', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#yearbuilt - assume it is the same as the nearest property. This assumes properties all near to each other were built around the same time\n",
    "fillna_knn( df = df_train,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'yearbuilt', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#lot size square feet - not sure what to do about this one. Lets use nearest neighbours. Assume it has same lot size as property closest to it\n",
    "fillna_knn( df = df_train,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'lotsizesquarefeet', fraction = 0.15, n_neighbors = 1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "153ec1b7-e08f-4a26-9757-dd797bf9894b",
    "_uuid": "cd1d629aee2dbceb360839ee1c6b90b42fc7ceee"
   },
   "source": [
    "**finishedfloor1squarefeet** - this is most correlated with calculatedfinishedsquarefeet according to the heatmap so lets see if we can use calculatedfinishedsquarefeet to fill in some of the finishedfloor1squarefeet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "90385b15-18c9-4897-b7e2-106c3ce5ad2b",
    "_uuid": "17b5fdc42d0a3d9ad6a6c968e6fcc75e1a417893",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#There are some properties where finishedfloor1squarefeet and calculatedfinishedsquarefeetare are both exactly the same - probably because its a studio flat of some sort so that the area on the first floor is equivalent to the total area, lets see how many there are\n",
    "#For now assume if the number of stories is 1 then the finishedfloor1squarefeet is the same as calculatedfinishedsquarefeet\n",
    "df_train.loc[(df_train['finishedfloor1squarefeet'].isnull()) & (df_train['numberofstories']==1),'finishedfloor1squarefeet'] = df_train.loc[(df_train['finishedfloor1squarefeet'].isnull()) & (df_train['numberofstories']==1),'calculatedfinishedsquarefeet']\n",
    "\n",
    "#I also discovered that there seems to be two properties that have finishedfloor1squarefeet greater than calculated finishedsquarefeet. Notice also that they have big logerrors aswell - my guess is that the Zillow House price model found it difficult to predict these points due to the fact that they probably had potentially 'incorrect' data input values?\n",
    "#Discussion point - should we be removing these points or leave them in as they are or 'fix' them? I think it really depends on whether the test data has similar points which may be wrong as we'll want to predict big log errors for these incorrect points aswell I guess...\n",
    "#For now just remove them.\n",
    "print(df_train.loc[df_train['calculatedfinishedsquarefeet']<df_train['finishedfloor1squarefeet']])\n",
    "droprows = df_train.loc[df_train['calculatedfinishedsquarefeet']<df_train['finishedfloor1squarefeet']].index\n",
    "df_train = df_train.drop(droprows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8dcea82a-ddaa-48ca-a429-733aa8da9bb1",
    "_uuid": "8af32ada2025abea0f22956dc8aaf3572e4f3ffb",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#taxvaluedollarcnt & landtaxvaluedollarcnt - set it equal to the tax amount (most correlated value). Single story property so assume they are all the same\n",
    "df_train.loc[df_train.taxvaluedollarcnt.isnull(),'taxvaluedollarcnt'] = df_train.loc[df_train.taxvaluedollarcnt.isnull(),'taxamount']\n",
    "df_train.loc[df_train.landtaxvaluedollarcnt.isnull(),'landtaxvaluedollarcnt'] = df_train.loc[df_train.landtaxvaluedollarcnt.isnull(),'taxamount']\n",
    "\n",
    "#structure tax value dollar - fill this in using its most correlated variable\n",
    "x =  df_train.corr()\n",
    "print(x.structuretaxvaluedollarcnt.sort_values(ascending = False))\n",
    "\n",
    "#taxvaluedollarcnt is most correlated variable, let's see how they are related \n",
    "plt.figure(figsize=(12,12))\n",
    "sns.jointplot(x=df_train.structuretaxvaluedollarcnt.values, y=df_train.taxvaluedollarcnt.values)\n",
    "plt.ylabel('taxvaluedollarcnt', fontsize=12)\n",
    "plt.xlabel('structuretaxvaluedollarcnt', fontsize=12)\n",
    "plt.title(\"structuretaxvaluedollarcnt Vs taxvaluedollarcnt\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "#Lets look at the distribution of taxvaluedollar cnt where structuretaxvaluedollarcnt is missing just to make sure we are predicting missing values in the body of the taxvaluedollarcnt distribution\n",
    "print(df_train.loc[df_train['structuretaxvaluedollarcnt'].isnull(),'taxvaluedollarcnt'].describe())\n",
    "print(df_train['taxvaluedollarcnt'].describe())\n",
    "\n",
    "#Slightly amend the k nearest neighbour function so it works on regression\n",
    "def fillna_knn_reg( df, base, target, n_neighbors = 5 ):\n",
    "    cols = base + [target]\n",
    "    X_train = df[cols]\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True).fit(X_train[base].values.reshape(-1, 1))\n",
    "    rescaledX = scaler.transform(X_train[base].values.reshape(-1, 1))\n",
    "\n",
    "    X_train = rescaledX[df[target].notnull()]\n",
    "    Y_train = df.loc[df[target].notnull(),target].values.reshape(-1, 1)\n",
    "\n",
    "    knn = KNeighborsRegressor(n_neighbors, n_jobs = -1)    \n",
    "    # fitting the model\n",
    "    knn.fit(X_train, Y_train)\n",
    "    # predict the response\n",
    "    X_test = rescaledX[df[target].isnull()]\n",
    "    pred = knn.predict(X_test)\n",
    "    df.loc[df_train[target].isnull(),target] = pred\n",
    "    return\n",
    "\n",
    "#fill in structuretaxvaluedollarcnt using taxvaluedollarcnt as per the above\n",
    "fillna_knn_reg(df = df_train, base = ['taxvaluedollarcnt'], target = 'structuretaxvaluedollarcnt')\n",
    "\n",
    "#Do the same thing for tax amount, as taxvaluedollarcnt is its most correlated variable\n",
    "fillna_knn_reg(df = df_train, base = ['taxvaluedollarcnt'], target = 'taxamount')\n",
    "print(df_train.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
